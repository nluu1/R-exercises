{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "316ee410",
   "metadata": {},
   "source": [
    "# Data Preprocessing Tools\n",
    "\n",
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c6ae1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- import [libraryname] as [shortcutname]\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt        #visualization\n",
    "import pandas as pd                    #dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4ca70b",
   "metadata": {},
   "source": [
    "## Importing the dataset\n",
    "\n",
    "### Locating the working directry and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf73772e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\Nhi\\Documents\\Udemy-exercises\\Machine-learning\n",
      "os.getcwd() returns an object of type: <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# Import the os module\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory: {0}\".format(cwd))\n",
    "\n",
    "# Print the type of the returned object\n",
    "print(\"os.getcwd() returns an object of type: {0}\".format(type(cwd)))\n",
    "\n",
    "#Set absolute path\n",
    "abs_path = 'C:/Users/Nhi/Documents/Udemy-exercises/Machine-learning/'\n",
    "\n",
    "#Change current working directory\n",
    "os.chdir(abs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76b0ef9",
   "metadata": {},
   "source": [
    "### Importing dataset and create entities for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b7ba7367",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Importing dataset\n",
    "\n",
    "# the dot \".\" is used when we want to access the attribte function from the library (in this case: panda library)\n",
    "dataset = pd.read_csv('../Machine-learning/dataset/Data.csv') #create dataframe from pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a3d0b041",
   "metadata": {},
   "outputs": [],
   "source": [
    "#---- Creatng entities for ML\n",
    "\n",
    "# [rows,columns] - in Python, lower-bound is included, but upper-bound is not\n",
    "# \":\" stands for all the rows\n",
    "# \"-1\" stands for \"last column\"; \":-1\" means all columns, exclude last column\n",
    "X = dataset.iloc[:, :-1].values\n",
    "\n",
    "Y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d3dec1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)  #independent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5363f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "print(Y)  # dependent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99afe1ff",
   "metadata": {},
   "source": [
    "## Taking care of missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8654257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sklearn library to handle missing datas\n",
    "from sklearn.impute import SimpleImputer\n",
    "    #library.module           #Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f01aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create instance of class (SimpleImputer) to utilize the tool\n",
    "\n",
    "#Create object for the class\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy = 'mean' )\n",
    "\n",
    "#apply object (imputer) on the matrix of features\n",
    "imputer.fit(X[:, 1:3])   # all rows, column age(1), and salary(2)\n",
    "\n",
    "#replace missing data\n",
    "X[:, 1:3] = imputer.transform(X[:, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8015b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 63777.77777777778]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' 38.77777777777778 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f4fac9",
   "metadata": {},
   "source": [
    "## Encoding categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc9e19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Assign numbers for string characters to access thru dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de6e8e5",
   "metadata": {},
   "source": [
    "### Encoding the independent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "addcf685",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe279d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create object and instances for Country names (index: 0)\n",
    "\n",
    "#-- ColumnTransformer( transformer argument, remainder argument)\n",
    "ct = ColumnTransformer(transformers= [('encoder',OneHotEncoder(),[0] )] , remainder= 'passthrough')\n",
    "\n",
    "#Transform the encodes to X with passing to numpy array\n",
    "X = np.array(ct.fit_transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f84d7224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)  #-- Countries are now assigned with unique ID from the 3 new columns created"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9136808f",
   "metadata": {},
   "source": [
    "### Encoding the Dependent Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "905dca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7bc57591",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "Y = le.fit_transform(Y)  #dependent variable does not need numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "850ab3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925ed7af",
   "metadata": {},
   "source": [
    "## Splitting the dataset into the Training set and Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192b8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Training set: train ML on existing obs\n",
    "\n",
    "#-- Test set: evaluate performance of model on new obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2c9e1b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#-- train_test_split(4 arguments: matrix of features, dependent variable, split size, fixed random factor )\n",
    "\n",
    "#recommended split size: 80% in training, 20% in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00471a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating 4 sets for future ML\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6565a067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 35.0 58000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f3812cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 30.0 54000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "71a3f5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a5f0383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9e9085",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7268ee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Scaling variables and features to make sure they all take values in the same scale\n",
    "# preventing one feature to dominte over the other, prevent ML to neglect the features\n",
    "\n",
    "#-- 2 techniques for feature scaling\n",
    "\n",
    "#1: Standardization: substract each value of features by the mean, dividing by the sdev\n",
    "    # all features will take the standard range (e.g: -1 & +3)\n",
    "    # work all the time\n",
    "\n",
    "#2: Nomalization: substract each value of features by minimum of features, dividing by the mode (max-min)\n",
    "   # all features will be between 0 and 1\n",
    "   # recommended when there's normal distribution or specific situation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "903f3f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- Standardization technique\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e0e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- FIT: get the mean and sd of each feature\n",
    "\n",
    "#--- TRANSFORM: apply the formula to transform te values so all can be in the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4581a4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "# We DO NOT have to always apply feature scaling the dummy variable to the matrix of features\n",
    "# Because Standardization will transform all the features and if our dummy has already taken the standard range, we do not need to\n",
    "\n",
    "#Thus, we will not standardize country names, but only \"Age\"(index:3) and \"Salary\"(index:5)\n",
    "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
    "\n",
    "#Transform test set with the SAME SCALE as the train set:\n",
    "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a67daa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
      " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
      " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
      " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
      " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
      " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
      " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
      " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)  #age and salary are transformed between -2:+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7658b503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
      " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
